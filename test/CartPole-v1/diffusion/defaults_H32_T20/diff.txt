diff --git a/config/locomotion.py b/config/locomotion.py
index 90edd41..53f9ad1 100644
--- a/config/locomotion.py
+++ b/config/locomotion.py
@@ -53,7 +53,7 @@ base = {
         'learning_rate': 2e-4,
         'gradient_accumulate_every': 2,
         'ema_decay': 0.995,
-        'save_freq': 20000,
+        'save_freq': 5000,
         'sample_freq': 20000,
         'n_saves': 5,
         'save_parallel': False,
@@ -92,11 +92,11 @@ base = {
         'n_steps_per_epoch': 10000,
         'loss_type': 'value_l2',
         'n_train_steps': 200e3,
-        'batch_size': 32,
+        'batch_size': 512,
         'learning_rate': 2e-4,
         'gradient_accumulate_every': 2,
         'ema_decay': 0.995,
-        'save_freq': 1000,
+        'save_freq': 5000,
         'sample_freq': 0,
         'n_saves': 5,
         'save_parallel': False,
diff --git a/diffuser/datasets/buffer.py b/diffuser/datasets/buffer.py
index 1ad2106..6d5529b 100644
--- a/diffuser/datasets/buffer.py
+++ b/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
@@ -76,7 +76,7 @@ class ReplayBuffer:
 
         ## penalize early termination
         if path['terminals'].any() and self.termination_penalty is not None:
-            assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
+            #assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
             self._dict['rewards'][self._count, path_length - 1] += self.termination_penalty
 
         ## record path length
diff --git a/diffuser/datasets/d4rl.py b/diffuser/datasets/d4rl.py
index 8ade6a0..f5858fb 100644
--- a/diffuser/datasets/d4rl.py
+++ b/diffuser/datasets/d4rl.py
@@ -3,13 +3,13 @@ import collections
 import numpy as np
 import gym
 import pdb
-
+import pickle
 from contextlib import (
     contextmanager,
     redirect_stderr,
     redirect_stdout,
 )
-
+print("aaaaaa")
 @contextmanager
 def suppress_output():
     """
@@ -20,9 +20,9 @@ def suppress_output():
         with redirect_stderr(fnull) as err, redirect_stdout(fnull) as out:
             yield (err, out)
 
-with suppress_output():
+#with suppress_output():
     ## d4rl prints out a variety of warnings
-    import d4rl
+    #import d4rl
 
 #-----------------------------------------------------------------------------#
 #-------------------------------- general api --------------------------------#
@@ -40,8 +40,15 @@ def load_environment(name):
     return env
 
 def get_dataset(env):
-    dataset = env.get_dataset()
 
+    if(env.unwrapped.spec.id=='CartPole-v1'):
+        with open('/home/fernandi/projects/diffuser/history/history.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+            print("loaded pickle")
+    else:
+        dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
         ## involving trajectory segmentation, so manually reset
@@ -78,18 +85,23 @@ def sequence_dataset(env, preprocess_fn):
     use_timeouts = 'timeouts' in dataset
 
     episode_step = 0
+    idx = 0
+    idx2= 0
     for i in range(N):
         done_bool = bool(dataset['terminals'][i])
+        
         if use_timeouts:
             final_timestep = dataset['timeouts'][i]
+            #print("final",final_timestep )
         else:
-            final_timestep = (episode_step == env._max_episode_steps - 1)
-
+            #final_timestep = (episode_step == env._max_episode_steps - 1)
+            final_timestep = (episode_step == 500 - 1)
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
 
-        if done_bool or final_timestep:
+        if done_bool:
+            
             episode_step = 0
             episode_data = {}
             for k in data_:
diff --git a/diffuser/datasets/sequence.py b/diffuser/datasets/sequence.py
index aee0c41..bf34273 100644
--- a/diffuser/datasets/sequence.py
+++ b/diffuser/datasets/sequence.py
@@ -1,7 +1,6 @@
 from collections import namedtuple
 import numpy as np
 import torch
-import pdb
 
 from .preprocessing import get_preprocess_fn
 from .d4rl import load_environment, sequence_dataset
@@ -28,6 +27,7 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
         for i, episode in enumerate(itr):
+            # print(f"i: {i}")
             fields.add_path(episode)
         fields.finalize()
 
@@ -41,7 +41,6 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.path_lengths = fields.path_lengths
         self.normalize()
 
-        print(fields)
         # shapes = {key: val.shape for key, val in self.fields.items()}
         # print(f'[ datasets/mujoco ] Dataset fields: {shapes}')
 
diff --git a/diffuser/models/diffusion.py b/diffuser/models/diffusion.py
index b717560..c8c3f54 100644
--- a/diffuser/models/diffusion.py
+++ b/diffuser/models/diffusion.py
@@ -135,6 +135,7 @@ class GaussianDiffusion(nn.Module):
             return noise
 
     def q_posterior(self, x_start, x_t, t):
+        #remove noise
         posterior_mean = (
             extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +
             extract(self.posterior_mean_coef2, t, x_t.shape) * x_t
@@ -194,7 +195,8 @@ class GaussianDiffusion(nn.Module):
 
     #------------------------------------------ training ------------------------------------------#
 
-    def q_sample(self, x_start, t, noise=None):
+    def q_sample(self, x_start, t, noise=None): 
+        #Add noise
         if noise is None:
             noise = torch.randn_like(x_start)
 
diff --git a/diffuser/utils/logger.py b/diffuser/utils/logger.py
index a06cc65..444c8c0 100644
--- a/diffuser/utils/logger.py
+++ b/diffuser/utils/logger.py
@@ -20,21 +20,21 @@ class Logger:
             samples.observations,
         )
 
-        ## render video of plans
-        self.renderer.render_plan(
-            os.path.join(self.savepath, f'{t}_plan.mp4'),
-            samples.actions[:self.max_render],
-            samples.observations[:self.max_render],
-            state,
-        )
-
-        if rollout is not None:
-            ## render video of rollout thus far
-            self.renderer.render_rollout(
-                os.path.join(self.savepath, f'rollout.mp4'),
-                rollout,
-                fps=80,
-            )
+        # ## render video of plans
+        # self.renderer.render_plan(
+        #     os.path.join(self.savepath, f'{t}_plan.mp4'),
+        #     samples.actions[:self.max_render],
+        #     samples.observations[:self.max_render],
+        #     state,
+        # )
+
+        # if rollout is not None:
+        #     # render video of rollout thus far
+        #     self.renderer.render_rollout(
+        #         os.path.join(self.savepath, f'rollout.mp4'),
+        #         rollout,
+        #         fps=80,
+        #     )
 
     def finish(self, t, score, total_reward, terminal, diffusion_experiment, value_experiment):
         json_path = os.path.join(self.savepath, 'rollout.json')
diff --git a/diffuser/utils/rendering.py b/diffuser/utils/rendering.py
index 8659ff1..ff25576 100644
--- a/diffuser/utils/rendering.py
+++ b/diffuser/utils/rendering.py
@@ -1,15 +1,18 @@
+
 import os
 import numpy as np
 import einops
 import imageio
 import matplotlib.pyplot as plt
+
 from matplotlib.colors import ListedColormap
 import gym
-import mujoco_py as mjc
+#import mujoco_py as mjc
 import warnings
 import pdb
 
 from .arrays import to_np
+
 from .video import save_video, save_videos
 
 from diffuser.datasets.d4rl import load_environment
diff --git a/diffuser/utils/training.py b/diffuser/utils/training.py
index fc5d033..582f6ca 100644
--- a/diffuser/utils/training.py
+++ b/diffuser/utils/training.py
@@ -52,6 +52,7 @@ class Trainer(object):
         results_folder='./results',
         n_reference=8,
         bucket=None,
+        wandb =None
     ):
         super().__init__()
         self.model = diffusion_model
@@ -65,16 +66,16 @@ class Trainer(object):
         self.save_freq = save_freq
         self.label_freq = label_freq
         self.save_parallel = save_parallel
-
+        self.wandb = wandb
         self.batch_size = train_batch_size
         self.gradient_accumulate_every = gradient_accumulate_every
 
         self.dataset = dataset
         self.dataloader = cycle(torch.utils.data.DataLoader(
-            self.dataset, batch_size=train_batch_size, num_workers=1, shuffle=True, pin_memory=True
+            self.dataset, batch_size=train_batch_size, num_workers=3, shuffle=True, pin_memory=True
         ))
         self.dataloader_vis = cycle(torch.utils.data.DataLoader(
-            self.dataset, batch_size=1, num_workers=0, shuffle=True, pin_memory=True
+            self.dataset, batch_size=1, num_workers=3, shuffle=True, pin_memory=True
         ))
         self.renderer = renderer
         self.optimizer = torch.optim.Adam(diffusion_model.parameters(), lr=train_lr)
@@ -119,11 +120,16 @@ class Trainer(object):
 
             if self.step % self.save_freq == 0:
                 label = self.step // self.label_freq * self.label_freq
-                self.save(label)
+                self.save(self.step)
 
             if self.step % self.log_freq == 0:
                 infos_str = ' | '.join([f'{key}: {val:8.4f}' for key, val in infos.items()])
                 print(f'{self.step}: {loss:8.4f} | {infos_str} | t: {timer():8.4f}', flush=True)
+                log = {}
+                for key, val in infos.items():
+                    log[key] = val
+                log["loss"] = loss
+                self.wandb.log(log)
 
             if self.step == 0 and self.sample_freq:
                 self.render_reference(self.n_reference)
@@ -171,7 +177,7 @@ class Trainer(object):
 
         ## get a temporary dataloader to load a single batch
         dataloader_tmp = cycle(torch.utils.data.DataLoader(
-            self.dataset, batch_size=batch_size, num_workers=0, shuffle=True, pin_memory=True
+            self.dataset, batch_size=batch_size, num_workers=1, shuffle=True, pin_memory=True
         ))
         batch = dataloader_tmp.__next__()
         dataloader_tmp.close()
@@ -185,7 +191,7 @@ class Trainer(object):
         observations = self.dataset.normalizer.unnormalize(normed_observations, 'observations')
 
         savepath = os.path.join(self.logdir, f'_sample-reference.png')
-        self.renderer.composite(savepath, observations)
+        #self.renderer.composite(savepath, observations)
 
     def render_samples(self, batch_size=2, n_samples=2):
         '''
@@ -224,4 +230,4 @@ class Trainer(object):
             observations = self.dataset.normalizer.unnormalize(normed_observations, 'observations')
 
             savepath = os.path.join(self.logdir, f'sample-{self.step}-{i}.png')
-            self.renderer.composite(savepath, observations)
+            #self.renderer.composite(savepath, observations)
diff --git a/diffuser/utils/video.py b/diffuser/utils/video.py
index 8ff2624..01770c0 100644
--- a/diffuser/utils/video.py
+++ b/diffuser/utils/video.py
@@ -10,7 +10,7 @@ def _make_dir(filename):
 def save_video(filename, video_frames, fps=60, video_format='mp4'):
     assert fps == int(fps), fps
     _make_dir(filename)
-
+    print("hola")
     skvideo.io.vwrite(
         filename,
         video_frames,
diff --git a/environment.yml b/environment.yml
index c14a0cf..287be77 100644
--- a/environment.yml
+++ b/environment.yml
@@ -1,11 +1,15 @@
-name: diffuser
+name: dif
 channels:
 - defaults
 - conda-forge
+- menpo 
 dependencies:
 - python=3.8
 - pip
 - patchelf
+- glew
+- mesalib
+- glfw3
 - pip:
     - -f https://download.pytorch.org/whl/torch_stable.html
     - numpy
diff --git a/scripts/train.py b/scripts/train.py
index 502837e..21f8df2 100644
--- a/scripts/train.py
+++ b/scripts/train.py
@@ -1,5 +1,8 @@
+print("before")
 import diffuser.utils as utils
-
+import torch
+import wandb
+print("after utils")
 
 #-----------------------------------------------------------------------------#
 #----------------------------------- setup -----------------------------------#
@@ -11,7 +14,14 @@ class Parser(utils.Parser):
 
 args = Parser().parse_args('diffusion')
 
-
+# start a new wandb run to track this script
+wandb.init(
+    # set the wandb project where this run will be logged
+    project="diffuser",
+    entity="diegofc",
+    # track hyperparameters and run metadata
+    config=args
+)
 #-----------------------------------------------------------------------------#
 #---------------------------------- dataset ----------------------------------#
 #-----------------------------------------------------------------------------#
@@ -75,7 +85,7 @@ diffusion_config = utils.Config(
 trainer_config = utils.Config(
     utils.Trainer,
     savepath=(args.savepath, 'trainer_config.pkl'),
-    train_batch_size=args.batch_size,
+    train_batch_size=256,
     train_lr=args.learning_rate,
     gradient_accumulate_every=args.gradient_accumulate_every,
     ema_decay=args.ema_decay,
@@ -86,6 +96,7 @@ trainer_config = utils.Config(
     results_folder=args.savepath,
     bucket=args.bucket,
     n_reference=args.n_reference,
+
 )
 
 #-----------------------------------------------------------------------------#
@@ -96,7 +107,7 @@ model = model_config()
 
 diffusion = diffusion_config(model)
 
-trainer = trainer_config(diffusion, dataset, renderer)
+trainer = trainer_config(diffusion, dataset, renderer, wandb =wandb)
 
 
 #-----------------------------------------------------------------------------#
@@ -116,9 +127,21 @@ print('✓')
 #--------------------------------- main loop ---------------------------------#
 #-----------------------------------------------------------------------------#
 
+def cycle(dl):
+    while True:
+        for data in dl:
+            yield data
+
 n_epochs = int(args.n_train_steps // args.n_steps_per_epoch)
 
+# dataloader = cycle(torch.utils.data.DataLoader(
+#             dataset, batch_size=64, num_workers=3, shuffle=True, pin_memory=True
+#         ))
+# batch = next(dataloader)
+
+# print(batch)
+
 for i in range(n_epochs):
     print(f'Epoch {i} / {n_epochs} | {args.savepath}')
     trainer.train(n_train_steps=args.n_steps_per_epoch)
-
+wandb.finish()
diff --git a/scripts/train_values.py b/scripts/train_values.py
index 4de3d77..84e9f70 100644
--- a/scripts/train_values.py
+++ b/scripts/train_values.py
@@ -12,7 +12,7 @@ class Parser(utils.Parser):
 
 args = Parser().parse_args('values')
 
-
+print(args.dataset)
 #-----------------------------------------------------------------------------#
 #---------------------------------- dataset ----------------------------------#
 #-----------------------------------------------------------------------------#
@@ -68,11 +68,10 @@ diffusion_config = utils.Config(
     loss_type=args.loss_type,
     device=args.device,
 )
-
 trainer_config = utils.Config(
     utils.Trainer,
     savepath=(args.savepath, 'trainer_config.pkl'),
-    train_batch_size=args.batch_size,
+    train_batch_size=256,
     train_lr=args.learning_rate,
     gradient_accumulate_every=args.gradient_accumulate_every,
     ema_decay=args.ema_decay,