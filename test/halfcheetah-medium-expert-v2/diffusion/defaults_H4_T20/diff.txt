diff --git a/config/locomotion.py b/config/locomotion.py
index 90edd41..53f9ad1 100644
--- a/config/locomotion.py
+++ b/config/locomotion.py
@@ -53,7 +53,7 @@ base = {
         'learning_rate': 2e-4,
         'gradient_accumulate_every': 2,
         'ema_decay': 0.995,
-        'save_freq': 20000,
+        'save_freq': 5000,
         'sample_freq': 20000,
         'n_saves': 5,
         'save_parallel': False,
@@ -92,11 +92,11 @@ base = {
         'n_steps_per_epoch': 10000,
         'loss_type': 'value_l2',
         'n_train_steps': 200e3,
-        'batch_size': 32,
+        'batch_size': 512,
         'learning_rate': 2e-4,
         'gradient_accumulate_every': 2,
         'ema_decay': 0.995,
-        'save_freq': 1000,
+        'save_freq': 5000,
         'sample_freq': 0,
         'n_saves': 5,
         'save_parallel': False,
diff --git a/diffuser/datasets/buffer.py b/diffuser/datasets/buffer.py
index 1ad2106..6d5529b 100644
--- a/diffuser/datasets/buffer.py
+++ b/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
@@ -76,7 +76,7 @@ class ReplayBuffer:
 
         ## penalize early termination
         if path['terminals'].any() and self.termination_penalty is not None:
-            assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
+            #assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
             self._dict['rewards'][self._count, path_length - 1] += self.termination_penalty
 
         ## record path length
diff --git a/diffuser/datasets/d4rl.py b/diffuser/datasets/d4rl.py
index 8ade6a0..f5858fb 100644
--- a/diffuser/datasets/d4rl.py
+++ b/diffuser/datasets/d4rl.py
@@ -3,13 +3,13 @@ import collections
 import numpy as np
 import gym
 import pdb
-
+import pickle
 from contextlib import (
     contextmanager,
     redirect_stderr,
     redirect_stdout,
 )
-
+print("aaaaaa")
 @contextmanager
 def suppress_output():
     """
@@ -20,9 +20,9 @@ def suppress_output():
         with redirect_stderr(fnull) as err, redirect_stdout(fnull) as out:
             yield (err, out)
 
-with suppress_output():
+#with suppress_output():
     ## d4rl prints out a variety of warnings
-    import d4rl
+    #import d4rl
 
 #-----------------------------------------------------------------------------#
 #-------------------------------- general api --------------------------------#
@@ -40,8 +40,15 @@ def load_environment(name):
     return env
 
 def get_dataset(env):
-    dataset = env.get_dataset()
 
+    if(env.unwrapped.spec.id=='CartPole-v1'):
+        with open('/home/fernandi/projects/diffuser/history/history.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+            print("loaded pickle")
+    else:
+        dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
         ## involving trajectory segmentation, so manually reset
@@ -78,18 +85,23 @@ def sequence_dataset(env, preprocess_fn):
     use_timeouts = 'timeouts' in dataset
 
     episode_step = 0
+    idx = 0
+    idx2= 0
     for i in range(N):
         done_bool = bool(dataset['terminals'][i])
+        
         if use_timeouts:
             final_timestep = dataset['timeouts'][i]
+            #print("final",final_timestep )
         else:
-            final_timestep = (episode_step == env._max_episode_steps - 1)
-
+            #final_timestep = (episode_step == env._max_episode_steps - 1)
+            final_timestep = (episode_step == 500 - 1)
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
 
-        if done_bool or final_timestep:
+        if done_bool:
+            
             episode_step = 0
             episode_data = {}
             for k in data_:
diff --git a/diffuser/datasets/sequence.py b/diffuser/datasets/sequence.py
index aee0c41..bf34273 100644
--- a/diffuser/datasets/sequence.py
+++ b/diffuser/datasets/sequence.py
@@ -1,7 +1,6 @@
 from collections import namedtuple
 import numpy as np
 import torch
-import pdb
 
 from .preprocessing import get_preprocess_fn
 from .d4rl import load_environment, sequence_dataset
@@ -28,6 +27,7 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
         for i, episode in enumerate(itr):
+            # print(f"i: {i}")
             fields.add_path(episode)
         fields.finalize()
 
@@ -41,7 +41,6 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.path_lengths = fields.path_lengths
         self.normalize()
 
-        print(fields)
         # shapes = {key: val.shape for key, val in self.fields.items()}
         # print(f'[ datasets/mujoco ] Dataset fields: {shapes}')
 
diff --git a/diffuser/models/diffusion.py b/diffuser/models/diffusion.py
index b717560..c8c3f54 100644
--- a/diffuser/models/diffusion.py
+++ b/diffuser/models/diffusion.py
@@ -135,6 +135,7 @@ class GaussianDiffusion(nn.Module):
             return noise
 
     def q_posterior(self, x_start, x_t, t):
+        #remove noise
         posterior_mean = (
             extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +
             extract(self.posterior_mean_coef2, t, x_t.shape) * x_t
@@ -194,7 +195,8 @@ class GaussianDiffusion(nn.Module):
 
     #------------------------------------------ training ------------------------------------------#
 
-    def q_sample(self, x_start, t, noise=None):
+    def q_sample(self, x_start, t, noise=None): 
+        #Add noise
         if noise is None:
             noise = torch.randn_like(x_start)
 
diff --git a/diffuser/utils/__init__.py b/diffuser/utils/__init__.py
index 01eb59b..30b51af 100644
--- a/diffuser/utils/__init__.py
+++ b/diffuser/utils/__init__.py
@@ -1,9 +1,14 @@
 from .serialization import *
+print("1")
 from .training import *
 from .progress import *
 from .setup import *
 from .config import *
+print("2")
 from .rendering import *
+print("2df")
 from .arrays import *
+print("2dfd")
 from .colab import *
+print("3")
 from .logger import *
diff --git a/diffuser/utils/logger.py b/diffuser/utils/logger.py
index a06cc65..444c8c0 100644
--- a/diffuser/utils/logger.py
+++ b/diffuser/utils/logger.py
@@ -20,21 +20,21 @@ class Logger:
             samples.observations,
         )
 
-        ## render video of plans
-        self.renderer.render_plan(
-            os.path.join(self.savepath, f'{t}_plan.mp4'),
-            samples.actions[:self.max_render],
-            samples.observations[:self.max_render],
-            state,
-        )
-
-        if rollout is not None:
-            ## render video of rollout thus far
-            self.renderer.render_rollout(
-                os.path.join(self.savepath, f'rollout.mp4'),
-                rollout,
-                fps=80,
-            )
+        # ## render video of plans
+        # self.renderer.render_plan(
+        #     os.path.join(self.savepath, f'{t}_plan.mp4'),
+        #     samples.actions[:self.max_render],
+        #     samples.observations[:self.max_render],
+        #     state,
+        # )
+
+        # if rollout is not None:
+        #     # render video of rollout thus far
+        #     self.renderer.render_rollout(
+        #         os.path.join(self.savepath, f'rollout.mp4'),
+        #         rollout,
+        #         fps=80,
+        #     )
 
     def finish(self, t, score, total_reward, terminal, diffusion_experiment, value_experiment):
         json_path = os.path.join(self.savepath, 'rollout.json')
diff --git a/diffuser/utils/rendering.py b/diffuser/utils/rendering.py
index 8659ff1..3f2fd5f 100644
--- a/diffuser/utils/rendering.py
+++ b/diffuser/utils/rendering.py
@@ -1,19 +1,28 @@
+
+print("load_env")
 import os
 import numpy as np
 import einops
 import imageio
 import matplotlib.pyplot as plt
+print("load_env2")
+
 from matplotlib.colors import ListedColormap
 import gym
-import mujoco_py as mjc
+#import mujoco_py as mjc
 import warnings
 import pdb
+print("load_env22")
 
 from .arrays import to_np
+print("load_envssdd")
+
 from .video import save_video, save_videos
+print("load_envssdd")
 
 from diffuser.datasets.d4rl import load_environment
 
+print("load_envss")
 #-----------------------------------------------------------------------------#
 #------------------------------- helper structs ------------------------------#
 #-----------------------------------------------------------------------------#
@@ -55,186 +64,186 @@ class MuJoCoRenderer:
         default mujoco renderer
     '''
 
-    def __init__(self, env):
-        if type(env) is str:
-            env = env_map(env)
-            self.env = gym.make(env)
-        else:
-            self.env = env
-        ## - 1 because the envs in renderer are fully-observed
-        self.observation_dim = np.prod(self.env.observation_space.shape) - 1
-        self.action_dim = np.prod(self.env.action_space.shape)
-        try:
-            self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
-        except:
-            print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
-            self.viewer = None
-
-    def pad_observation(self, observation):
-        state = np.concatenate([
-            np.zeros(1),
-            observation,
-        ])
-        return state
-
-    def pad_observations(self, observations):
-        qpos_dim = self.env.sim.data.qpos.size
-        ## xpos is hidden
-        xvel_dim = qpos_dim - 1
-        xvel = observations[:, xvel_dim]
-        xpos = np.cumsum(xvel) * self.env.dt
-        states = np.concatenate([
-            xpos[:,None],
-            observations,
-        ], axis=-1)
-        return states
-
-    def render(self, observation, dim=256, partial=False, qvel=True, render_kwargs=None, conditions=None):
-
-        if type(dim) == int:
-            dim = (dim, dim)
-
-        if self.viewer is None:
-            return np.zeros((*dim, 3), np.uint8)
-
-        if render_kwargs is None:
-            xpos = observation[0] if not partial else 0
-            render_kwargs = {
-                'trackbodyid': 2,
-                'distance': 3,
-                'lookat': [xpos, -0.5, 1],
-                'elevation': -20
-            }
-
-        for key, val in render_kwargs.items():
-            if key == 'lookat':
-                self.viewer.cam.lookat[:] = val[:]
-            else:
-                setattr(self.viewer.cam, key, val)
-
-        if partial:
-            state = self.pad_observation(observation)
-        else:
-            state = observation
-
-        qpos_dim = self.env.sim.data.qpos.size
-        if not qvel or state.shape[-1] == qpos_dim:
-            qvel_dim = self.env.sim.data.qvel.size
-            state = np.concatenate([state, np.zeros(qvel_dim)])
-
-        set_state(self.env, state)
-
-        self.viewer.render(*dim)
-        data = self.viewer.read_pixels(*dim, depth=False)
-        data = data[::-1, :, :]
-        return data
-
-    def _renders(self, observations, **kwargs):
-        images = []
-        for observation in observations:
-            img = self.render(observation, **kwargs)
-            images.append(img)
-        return np.stack(images, axis=0)
-
-    def renders(self, samples, partial=False, **kwargs):
-        if partial:
-            samples = self.pad_observations(samples)
-            partial = False
-
-        sample_images = self._renders(samples, partial=partial, **kwargs)
-
-        composite = np.ones_like(sample_images[0]) * 255
-
-        for img in sample_images:
-            mask = get_image_mask(img)
-            composite[mask] = img[mask]
-
-        return composite
-
-    def composite(self, savepath, paths, dim=(1024, 256), **kwargs):
-
-        render_kwargs = {
-            'trackbodyid': 2,
-            'distance': 10,
-            'lookat': [5, 2, 0.5],
-            'elevation': 0
-        }
-        images = []
-        for path in paths:
-            ## [ H x obs_dim ]
-            path = atmost_2d(path)
-            img = self.renders(to_np(path), dim=dim, partial=True, qvel=True, render_kwargs=render_kwargs, **kwargs)
-            images.append(img)
-        images = np.concatenate(images, axis=0)
-
-        if savepath is not None:
-            imageio.imsave(savepath, images)
-            print(f'Saved {len(paths)} samples to: {savepath}')
-
-        return images
-
-    def render_rollout(self, savepath, states, **video_kwargs):
-        if type(states) is list: states = np.array(states)
-        images = self._renders(states, partial=True)
-        save_video(savepath, images, **video_kwargs)
-
-    def render_plan(self, savepath, actions, observations_pred, state, fps=30):
-        ## [ batch_size x horizon x observation_dim ]
-        observations_real = rollouts_from_state(self.env, state, actions)
-
-        ## there will be one more state in `observations_real`
-        ## than in `observations_pred` because the last action
-        ## does not have an associated next_state in the sampled trajectory
-        observations_real = observations_real[:,:-1]
-
-        images_pred = np.stack([
-            self._renders(obs_pred, partial=True)
-            for obs_pred in observations_pred
-        ])
-
-        images_real = np.stack([
-            self._renders(obs_real, partial=False)
-            for obs_real in observations_real
-        ])
-
-        ## [ batch_size x horizon x H x W x C ]
-        images = np.concatenate([images_pred, images_real], axis=-2)
-        save_videos(savepath, *images)
-
-    def render_diffusion(self, savepath, diffusion_path, **video_kwargs):
-        '''
-            diffusion_path : [ n_diffusion_steps x batch_size x 1 x horizon x joined_dim ]
-        '''
-        render_kwargs = {
-            'trackbodyid': 2,
-            'distance': 10,
-            'lookat': [10, 2, 0.5],
-            'elevation': 0,
-        }
-
-        diffusion_path = to_np(diffusion_path)
-
-        n_diffusion_steps, batch_size, _, horizon, joined_dim = diffusion_path.shape
-
-        frames = []
-        for t in reversed(range(n_diffusion_steps)):
-            print(f'[ utils/renderer ] Diffusion: {t} / {n_diffusion_steps}')
-
-            ## [ batch_size x horizon x observation_dim ]
-            states_l = diffusion_path[t].reshape(batch_size, horizon, joined_dim)[:, :, :self.observation_dim]
-
-            frame = []
-            for states in states_l:
-                img = self.composite(None, states, dim=(1024, 256), partial=True, qvel=True, render_kwargs=render_kwargs)
-                frame.append(img)
-            frame = np.concatenate(frame, axis=0)
-
-            frames.append(frame)
-
-        save_video(savepath, frames, **video_kwargs)
-
-    def __call__(self, *args, **kwargs):
-        return self.renders(*args, **kwargs)
+    # def __init__(self, env):
+    #     if type(env) is str:
+    #         env = env_map(env)
+    #         self.env = gym.make(env)
+    #     else:
+    #         self.env = env
+    #     ## - 1 because the envs in renderer are fully-observed
+    #     self.observation_dim = np.prod(self.env.observation_space.shape) - 1
+    #     self.action_dim = np.prod(self.env.action_space.shape)
+    #     try:
+    #         self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
+    #     except:
+    #         print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
+    #         self.viewer = None
+
+    # def pad_observation(self, observation):
+    #     state = np.concatenate([
+    #         np.zeros(1),
+    #         observation,
+    #     ])
+    #     return state
+
+    # def pad_observations(self, observations):
+    #     qpos_dim = self.env.sim.data.qpos.size
+    #     ## xpos is hidden
+    #     xvel_dim = qpos_dim - 1
+    #     xvel = observations[:, xvel_dim]
+    #     xpos = np.cumsum(xvel) * self.env.dt
+    #     states = np.concatenate([
+    #         xpos[:,None],
+    #         observations,
+    #     ], axis=-1)
+    #     return states
+
+    # def render(self, observation, dim=256, partial=False, qvel=True, render_kwargs=None, conditions=None):
+
+    #     if type(dim) == int:
+    #         dim = (dim, dim)
+
+    #     if self.viewer is None:
+    #         return np.zeros((*dim, 3), np.uint8)
+
+    #     if render_kwargs is None:
+    #         xpos = observation[0] if not partial else 0
+    #         render_kwargs = {
+    #             'trackbodyid': 2,
+    #             'distance': 3,
+    #             'lookat': [xpos, -0.5, 1],
+    #             'elevation': -20
+    #         }
+
+    #     for key, val in render_kwargs.items():
+    #         if key == 'lookat':
+    #             self.viewer.cam.lookat[:] = val[:]
+    #         else:
+    #             setattr(self.viewer.cam, key, val)
+
+    #     if partial:
+    #         state = self.pad_observation(observation)
+    #     else:
+    #         state = observation
+
+    #     qpos_dim = self.env.sim.data.qpos.size
+    #     if not qvel or state.shape[-1] == qpos_dim:
+    #         qvel_dim = self.env.sim.data.qvel.size
+    #         state = np.concatenate([state, np.zeros(qvel_dim)])
+
+    #     set_state(self.env, state)
+
+    #     self.viewer.render(*dim)
+    #     data = self.viewer.read_pixels(*dim, depth=False)
+    #     data = data[::-1, :, :]
+    #     return data
+
+    # def _renders(self, observations, **kwargs):
+    #     images = []
+    #     for observation in observations:
+    #         img = self.render(observation, **kwargs)
+    #         images.append(img)
+    #     return np.stack(images, axis=0)
+
+    # def renders(self, samples, partial=False, **kwargs):
+    #     if partial:
+    #         samples = self.pad_observations(samples)
+    #         partial = False
+
+    #     sample_images = self._renders(samples, partial=partial, **kwargs)
+
+    #     composite = np.ones_like(sample_images[0]) * 255
+
+    #     for img in sample_images:
+    #         mask = get_image_mask(img)
+    #         composite[mask] = img[mask]
+
+    #     return composite
+
+    # def composite(self, savepath, paths, dim=(1024, 256), **kwargs):
+
+    #     render_kwargs = {
+    #         'trackbodyid': 2,
+    #         'distance': 10,
+    #         'lookat': [5, 2, 0.5],
+    #         'elevation': 0
+    #     }
+    #     images = []
+    #     for path in paths:
+    #         ## [ H x obs_dim ]
+    #         path = atmost_2d(path)
+    #         img = self.renders(to_np(path), dim=dim, partial=True, qvel=True, render_kwargs=render_kwargs, **kwargs)
+    #         images.append(img)
+    #     images = np.concatenate(images, axis=0)
+
+    #     if savepath is not None:
+    #         imageio.imsave(savepath, images)
+    #         print(f'Saved {len(paths)} samples to: {savepath}')
+
+    #     return images
+
+    # def render_rollout(self, savepath, states, **video_kwargs):
+    #     if type(states) is list: states = np.array(states)
+    #     images = self._renders(states, partial=True)
+    #     save_video(savepath, images, **video_kwargs)
+
+    # def render_plan(self, savepath, actions, observations_pred, state, fps=30):
+    #     ## [ batch_size x horizon x observation_dim ]
+    #     observations_real = rollouts_from_state(self.env, state, actions)
+
+    #     ## there will be one more state in `observations_real`
+    #     ## than in `observations_pred` because the last action
+    #     ## does not have an associated next_state in the sampled trajectory
+    #     observations_real = observations_real[:,:-1]
+
+    #     images_pred = np.stack([
+    #         self._renders(obs_pred, partial=True)
+    #         for obs_pred in observations_pred
+    #     ])
+
+    #     images_real = np.stack([
+    #         self._renders(obs_real, partial=False)
+    #         for obs_real in observations_real
+    #     ])
+
+    #     ## [ batch_size x horizon x H x W x C ]
+    #     images = np.concatenate([images_pred, images_real], axis=-2)
+    #     save_videos(savepath, *images)
+
+    # def render_diffusion(self, savepath, diffusion_path, **video_kwargs):
+    #     '''
+    #         diffusion_path : [ n_diffusion_steps x batch_size x 1 x horizon x joined_dim ]
+    #     '''
+    #     render_kwargs = {
+    #         'trackbodyid': 2,
+    #         'distance': 10,
+    #         'lookat': [10, 2, 0.5],
+    #         'elevation': 0,
+    #     }
+
+    #     diffusion_path = to_np(diffusion_path)
+
+    #     n_diffusion_steps, batch_size, _, horizon, joined_dim = diffusion_path.shape
+
+    #     frames = []
+    #     for t in reversed(range(n_diffusion_steps)):
+    #         print(f'[ utils/renderer ] Diffusion: {t} / {n_diffusion_steps}')
+
+    #         ## [ batch_size x horizon x observation_dim ]
+    #         states_l = diffusion_path[t].reshape(batch_size, horizon, joined_dim)[:, :, :self.observation_dim]
+
+    #         frame = []
+    #         for states in states_l:
+    #             img = self.composite(None, states, dim=(1024, 256), partial=True, qvel=True, render_kwargs=render_kwargs)
+    #             frame.append(img)
+    #         frame = np.concatenate(frame, axis=0)
+
+    #         frames.append(frame)
+
+    #     save_video(savepath, frames, **video_kwargs)
+
+    # def __call__(self, *args, **kwargs):
+    #     return self.renders(*args, **kwargs)
 
 #-----------------------------------------------------------------------------#
 #---------------------------------- rollouts ---------------------------------#
diff --git a/diffuser/utils/training.py b/diffuser/utils/training.py
index fc5d033..d6b8ec0 100644
--- a/diffuser/utils/training.py
+++ b/diffuser/utils/training.py
@@ -71,10 +71,10 @@ class Trainer(object):
 
         self.dataset = dataset
         self.dataloader = cycle(torch.utils.data.DataLoader(
-            self.dataset, batch_size=train_batch_size, num_workers=1, shuffle=True, pin_memory=True
+            self.dataset, batch_size=train_batch_size, num_workers=3, shuffle=True, pin_memory=True
         ))
         self.dataloader_vis = cycle(torch.utils.data.DataLoader(
-            self.dataset, batch_size=1, num_workers=0, shuffle=True, pin_memory=True
+            self.dataset, batch_size=1, num_workers=3, shuffle=True, pin_memory=True
         ))
         self.renderer = renderer
         self.optimizer = torch.optim.Adam(diffusion_model.parameters(), lr=train_lr)
@@ -119,7 +119,7 @@ class Trainer(object):
 
             if self.step % self.save_freq == 0:
                 label = self.step // self.label_freq * self.label_freq
-                self.save(label)
+                self.save(self.step)
 
             if self.step % self.log_freq == 0:
                 infos_str = ' | '.join([f'{key}: {val:8.4f}' for key, val in infos.items()])
@@ -171,7 +171,7 @@ class Trainer(object):
 
         ## get a temporary dataloader to load a single batch
         dataloader_tmp = cycle(torch.utils.data.DataLoader(
-            self.dataset, batch_size=batch_size, num_workers=0, shuffle=True, pin_memory=True
+            self.dataset, batch_size=batch_size, num_workers=1, shuffle=True, pin_memory=True
         ))
         batch = dataloader_tmp.__next__()
         dataloader_tmp.close()
@@ -185,7 +185,7 @@ class Trainer(object):
         observations = self.dataset.normalizer.unnormalize(normed_observations, 'observations')
 
         savepath = os.path.join(self.logdir, f'_sample-reference.png')
-        self.renderer.composite(savepath, observations)
+        #self.renderer.composite(savepath, observations)
 
     def render_samples(self, batch_size=2, n_samples=2):
         '''
@@ -224,4 +224,4 @@ class Trainer(object):
             observations = self.dataset.normalizer.unnormalize(normed_observations, 'observations')
 
             savepath = os.path.join(self.logdir, f'sample-{self.step}-{i}.png')
-            self.renderer.composite(savepath, observations)
+            #self.renderer.composite(savepath, observations)
diff --git a/diffuser/utils/video.py b/diffuser/utils/video.py
index 8ff2624..01770c0 100644
--- a/diffuser/utils/video.py
+++ b/diffuser/utils/video.py
@@ -10,7 +10,7 @@ def _make_dir(filename):
 def save_video(filename, video_frames, fps=60, video_format='mp4'):
     assert fps == int(fps), fps
     _make_dir(filename)
-
+    print("hola")
     skvideo.io.vwrite(
         filename,
         video_frames,
diff --git a/environment.yml b/environment.yml
index c14a0cf..287be77 100644
--- a/environment.yml
+++ b/environment.yml
@@ -1,11 +1,15 @@
-name: diffuser
+name: dif
 channels:
 - defaults
 - conda-forge
+- menpo 
 dependencies:
 - python=3.8
 - pip
 - patchelf
+- glew
+- mesalib
+- glfw3
 - pip:
     - -f https://download.pytorch.org/whl/torch_stable.html
     - numpy
diff --git a/scripts/train.py b/scripts/train.py
index 502837e..309c416 100644
--- a/scripts/train.py
+++ b/scripts/train.py
@@ -1,5 +1,7 @@
+print("before")
 import diffuser.utils as utils
-
+import torch
+print("after utils")
 
 #-----------------------------------------------------------------------------#
 #----------------------------------- setup -----------------------------------#
@@ -75,7 +77,7 @@ diffusion_config = utils.Config(
 trainer_config = utils.Config(
     utils.Trainer,
     savepath=(args.savepath, 'trainer_config.pkl'),
-    train_batch_size=args.batch_size,
+    train_batch_size=256,
     train_lr=args.learning_rate,
     gradient_accumulate_every=args.gradient_accumulate_every,
     ema_decay=args.ema_decay,
@@ -116,8 +118,20 @@ print('✓')
 #--------------------------------- main loop ---------------------------------#
 #-----------------------------------------------------------------------------#
 
+def cycle(dl):
+    while True:
+        for data in dl:
+            yield data
+
 n_epochs = int(args.n_train_steps // args.n_steps_per_epoch)
 
+# dataloader = cycle(torch.utils.data.DataLoader(
+#             dataset, batch_size=64, num_workers=3, shuffle=True, pin_memory=True
+#         ))
+# batch = next(dataloader)
+
+# print(batch)
+
 for i in range(n_epochs):
     print(f'Epoch {i} / {n_epochs} | {args.savepath}')
     trainer.train(n_train_steps=args.n_steps_per_epoch)
diff --git a/scripts/train_values.py b/scripts/train_values.py
index 4de3d77..f29dbb7 100644
--- a/scripts/train_values.py
+++ b/scripts/train_values.py
@@ -12,7 +12,7 @@ class Parser(utils.Parser):
 
 args = Parser().parse_args('values')
 
-
+print(args.dataset)
 #-----------------------------------------------------------------------------#
 #---------------------------------- dataset ----------------------------------#
 #-----------------------------------------------------------------------------#
@@ -31,7 +31,7 @@ dataset_config = utils.Config(
     termination_penalty=args.termination_penalty,
     normed=args.normed,
 )
-
+import pdb;pdb.set_trace()
 render_config = utils.Config(
     args.renderer,
     savepath=(args.savepath, 'render_config.pkl'),
@@ -68,11 +68,10 @@ diffusion_config = utils.Config(
     loss_type=args.loss_type,
     device=args.device,
 )
-
 trainer_config = utils.Config(
     utils.Trainer,
     savepath=(args.savepath, 'trainer_config.pkl'),
-    train_batch_size=args.batch_size,
+    train_batch_size=256,
     train_lr=args.learning_rate,
     gradient_accumulate_every=args.gradient_accumulate_every,
     ema_decay=args.ema_decay,